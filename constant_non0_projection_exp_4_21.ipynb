{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from treeple.datasets import make_trunk_classification\n",
    "import ydf\n",
    "import matplotlib.pyplot as plt\n",
    "from treeple import ObliqueRandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import ListedColormap\n",
    "from treeple._lib.sklearn.tree._criterion import Gini\n",
    "from treeple.tree._oblique_splitter import BestObliqueSplitterTester\n",
    "from treeple.datasets import make_trunk_classification\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_proj_existing_data(X, y,\n",
    "                max_features=10, \n",
    "                feature_combinations=1.5,\n",
    "                plot_fig=True,\n",
    "                random_state=1):\n",
    "\n",
    "    criterion = Gini(1, np.array((0, 1)))\n",
    "\n",
    "    min_samples_leaf = 1\n",
    "    min_weight_leaf = 0.0\n",
    "    random_state = np.random.RandomState(random_state)\n",
    "    n_samples= X.shape[0]\n",
    "    n_features= X.shape[1]\n",
    "\n",
    "    #feature_combinations = 3.0\n",
    "    monotonic_cst = None\n",
    "    missing_value_feature_mask = None\n",
    "\n",
    "    # X, y = make_trunk_classification(n_samples=n_samples, n_dim=n_features, n_informative=600, seed=0)\n",
    "    y = y.reshape(-1,1).astype(np.float64)\n",
    "    X= X.astype(np.float32)\n",
    "\n",
    "    sample_weight = np.ones(n_samples)\n",
    "\n",
    "    splitter = BestObliqueSplitterTester(\n",
    "        criterion,\n",
    "        max_features,\n",
    "        min_samples_leaf,\n",
    "        min_weight_leaf,\n",
    "        random_state,\n",
    "        monotonic_cst,\n",
    "        feature_combinations,\n",
    "    )\n",
    "    splitter.init_test(X, y, sample_weight, missing_value_feature_mask)\n",
    "\n",
    "\n",
    "    projection_matrix = splitter.sample_projection_matrix_py()\n",
    "    print(\"projection matrix shape:\", projection_matrix.shape)\n",
    "\n",
    "\n",
    "    if plot_fig:\n",
    "        # Visualize the projection matrix\n",
    "        cmap = ListedColormap([\"orange\", \"white\", \"green\"])\n",
    "\n",
    "        # Create a heatmap to visualize the indices\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "        ax.imshow(projection_matrix, cmap=cmap, aspect=n_features / max_features, interpolation=\"none\")\n",
    "\n",
    "        ax.set(title=\"Sampled Projection Matrix\", xlabel=\"Feature Index\", ylabel=\"Projection Vector Index\")\n",
    "        ax.set_xticks(np.arange(n_features))\n",
    "        ax.set_yticks(np.arange(max_features))\n",
    "        ax.set_yticklabels(np.arange(max_features, dtype=int) + 1)\n",
    "        ax.set_xticklabels(np.arange(n_features, dtype=int) + 1)\n",
    "\n",
    "        # Create a mappable object\n",
    "        sm = ScalarMappable(cmap=cmap)\n",
    "        sm.set_array([])  # You can set an empty array or values here\n",
    "\n",
    "        # Create a color bar with labels for each feature set\n",
    "        colorbar = fig.colorbar(sm, ax=ax, ticks=[0, 0.5, 1], format=\"%d\")\n",
    "        colorbar.set_label(\"Projection Weight\")\n",
    "        colorbar.ax.set_yticklabels([\"-1\", \"0\", \"1\"])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    print(f\"n_feature = \", n_features, \n",
    "          \"\\nn_samples = \", n_samples, \n",
    "          \"\\nmax_features = \", max_features, \n",
    "          \"\\nfeature_combinations = \", feature_combinations)\n",
    "    print(\"max_features * feature_combinations = \", max_features * feature_combinations)\n",
    "    print(\"Number of non-zeros: \",len(projection_matrix.nonzero()[0]))\n",
    "    return projection_matrix, len(projection_matrix.nonzero()[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataframe(X, y):\n",
    "    df = pd.DataFrame(X)\n",
    "    df.columns = [str(i) for i in df.columns]  # Convert column names to strings\n",
    "    df[\"target\"] = y.astype(int)  # Append target column\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared hyperparameters that used for both models\n",
    "MAX_DEPTH = 10\n",
    "N_ESTIMATORS = 300\n",
    "RANDOM_SEED = 42\n",
    "N_JOBS=-1\n",
    "BOOTSTRAP = True\n",
    "MAX_FEATURE = 100\n",
    "FEATURE_COMBINATIONS = 3.0\n",
    "\n",
    "### ydf ###\n",
    "params_ydf = dict()\n",
    "params_ydf[\"label\"] = \"target\"\n",
    "params_ydf[\"max_depth\"] = MAX_DEPTH\n",
    "params_ydf[\"num_trees\"] = N_ESTIMATORS\n",
    "params_ydf[\"random_seed\"] = RANDOM_SEED\n",
    "params_ydf[\"honest\"] = False\n",
    "params_ydf[\"bootstrap_size_ratio\"] = 1.0\n",
    "params_ydf[\"bootstrap_training_dataset\"] = BOOTSTRAP\n",
    "params_ydf[\"categorical_algorithm\"] = \"ONE_HOT\"\n",
    "params_ydf[\"compute_oob_performances\"] = False  #oob_score\n",
    "params_ydf[\"compute_oob_variable_importances\"] = False  ## oob_score\n",
    "params_ydf[\"in_split_min_examples_check\"] = True\n",
    "params_ydf[\"min_examples\"] = 1    #min_samples_leaf\n",
    "params_ydf[\"keep_non_leaf_label_distribution\"] = True   # not sure\n",
    "\n",
    "params_ydf[\"max_num_nodes\"] = 30\n",
    "\n",
    "params_ydf[\"growing_strategy\"] = \"BEST_FIRST_GLOBAL\"\n",
    "# params_ydf[\"num_candidate_attributes\"] = -1  #0 equivalent to sqrt max_features in treeple\n",
    "params_ydf[\"num_candidate_attributes_ratio\"] = 1.0\n",
    "params_ydf[\"sorting_strategy\"] = \"IN_NODE\" ###\n",
    "# sparse oblique params\n",
    "params_ydf[\"split_axis\"] = \"SPARSE_OBLIQUE\"\n",
    "params_ydf[\"sparse_oblique_weights\"] = \"BINARY\"\n",
    "params_ydf[\"sparse_oblique_projection_density_factor\"] = FEATURE_COMBINATIONS\n",
    "params_ydf[\"sparse_oblique_normalization\"] = \"MIN_MAX\"\n",
    "params_ydf[\"sparse_oblique_max_num_projections\"] = MAX_FEATURE # modify this, find in sourse code in treeple\n",
    "params_ydf[\"sparse_oblique_num_projections_exponent\"] = 1.0   #2.0\n",
    "params_ydf[\"sampling_with_replacement\"] = False\n",
    "\n",
    "### treeple ObliqueRandomForestClassifier ###\n",
    "params_treeple = {}\n",
    "params_treeple[\"n_estimators\"] = N_ESTIMATORS\n",
    "params_treeple[\"criterion\"] = \"entropy\"\n",
    "params_treeple[\"max_depth\"] = MAX_DEPTH\n",
    "params_treeple[\"min_samples_split\"] = 2\n",
    "params_treeple[\"min_samples_leaf\"] = 1\n",
    "params_treeple[\"min_weight_fraction_leaf\"] = 0.0\n",
    "params_treeple[\"max_features\"] = MAX_FEATURE\n",
    "params_treeple[\"max_leaf_nodes\"] = 30\n",
    "params_treeple[\"min_impurity_decrease\"] = 0.0\n",
    "params_treeple[\"bootstrap\"] = BOOTSTRAP\n",
    "params_treeple[\"oob_score\"] = False\n",
    "params_treeple[\"n_jobs\"] = N_JOBS\n",
    "params_treeple[\"random_state\"] = RANDOM_SEED\n",
    "params_treeple[\"verbose\"] = 0\n",
    "params_treeple[\"warm_start\"] = False\n",
    "params_treeple[\"class_weight\"] = None\n",
    "params_treeple[\"max_samples\"] = None\n",
    "params_treeple[\"feature_combinations\"] = FEATURE_COMBINATIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant_nNonzeros_simulation(n_tree,\n",
    "                    n_samples, \n",
    "                    params_treeple, \n",
    "                    params_ydf,\n",
    "                    n_non_zeros,\n",
    "                    n_rows,\n",
    "                    n_columns,\n",
    "                    n_rep=2, \n",
    "                    plot=False):\n",
    "\n",
    "\n",
    "\n",
    "    accs_ydf = np.zeros((len(n_columns), len(n_rows)))\n",
    "    times_ydf = np.zeros(accs_ydf.shape)\n",
    "    accs_treeple = np.zeros(accs_ydf.shape)\n",
    "    times_treeple = np.zeros(accs_ydf.shape)\n",
    "\n",
    "    # copy the params to avoid overwriting\n",
    "    params_treeple1 = params_treeple.copy() \n",
    "    params_ydf1 = params_ydf.copy()\n",
    "    \n",
    "\n",
    "    for i, n_column in enumerate(n_columns):\n",
    "        # n_column matches number of features\n",
    "        max_features = n_column\n",
    "        X, y = make_trunk_classification(n_samples=n_samples, n_dim=n_column, n_informative=600, seed=0)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        df_train = prepare_dataframe(X_train, y_train)\n",
    "        df_test = prepare_dataframe(X_test, y_test)\n",
    "\n",
    "\n",
    "        for j, n_row in enumerate(n_rows):\n",
    "            # n_rows matches number of projections\n",
    "            n_dim= n_column\n",
    "\n",
    "            params_treeple1[\"max_features\"] = int(n_row)\n",
    "            params_treeple1[\"feature_combinations\"] = n_row\n",
    "\n",
    "            params_ydf1[\"sparse_oblique_max_num_projections\"] = int(n_row)\n",
    "            params_ydf1[\"Sparse_oblique_projection_density_factor\"] = n_row\n",
    "            \n",
    "            _, treeple_n_nonzeros = plot_proj_existing_data(X, y,\n",
    "                max_features=10, \n",
    "                feature_combinations=1.5,\n",
    "                plot_fig=False,\n",
    "                random_state=1)\n",
    "\n",
    "            print(\"=================================================\")        \n",
    "            print(f\"n_dim: {n_dim} | n_tree: {n_tree} | n_samples: {n_samples}\")\n",
    "            print(f\"n_row: {n_row} | n_column: {n_column} | n_non_zeros: {n_non_zeros}\")\n",
    "\n",
    "            \n",
    "            acc_temp_ydf=0\n",
    "            time_temp_ydf=0\n",
    "\n",
    "            acc_temp_treeple=0\n",
    "            time_temp_treeple=0\n",
    "\n",
    "            f1_temp=0\n",
    "\n",
    "            for _ in range(n_rep):\n",
    "                # --- Train YDF ---\n",
    "                learner = ydf.RandomForestLearner(**params_ydf1)\n",
    "                start_time = time.time()\n",
    "                ydf_model = learner.train(df_train)\n",
    "                time_ydf = time.time() - start_time\n",
    "                pred_ydf = ydf_model.predict(df_test)\n",
    "                pred_ydf = (pred_ydf >= 0.5).astype(int) \n",
    "\n",
    "                acc_ydf = accuracy_score(y_test, pred_ydf)\n",
    "                acc_temp_ydf+=acc_ydf\n",
    "                time_temp_ydf+=time_ydf\n",
    "            \n",
    "                # --- Train Treeple ---\n",
    "                treeple_model = ObliqueRandomForestClassifier(**params_treeple1)\n",
    "                acc_treeple, time_treeple, pred_treeple = train_and_evaluate(treeple_model, \"Treeple\", X_train, X_test, y_train, y_test)\n",
    "                acc_temp_treeple+=acc_treeple\n",
    "                time_temp_treeple+=time_treeple\n",
    "\n",
    "                # Calculate F1 score for two predictions\n",
    "                f1_compare = f1_score(pred_ydf, pred_treeple)\n",
    "                f1_temp+=f1_compare\n",
    "\n",
    "            accs_ydf.append(acc_temp_ydf/n_rep)\n",
    "            times_ydf.append(time_temp_ydf/n_rep)\n",
    "\n",
    "            accs_treeple.append(acc_temp_treeple/n_rep)\n",
    "            times_treeple.append(time_temp_treeple/n_rep)\n",
    "\n",
    "            f1_scores.append(f1_temp/n_rep)\n",
    "\n",
    "    return accs_ydf, times_ydf, accs_treeple, times_treeple, f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize n_rows and n_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = np.ones(6)\n",
    "n_rows[0] = 128\n",
    "n_rows.shape\n",
    "for i in range(0,n_rows.shape[0]-1):\n",
    "    n_rows[i+1] = n_rows[i]*2\n",
    "n_columns = n_rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "treeple1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
