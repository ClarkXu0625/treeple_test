{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import\n",
    "import treeple.tree._honest_tree\n",
    "from treeple.ensemble._supervised_forest import ObliqueRandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature normalization\n",
    "df_human = pd.read_excel('data/Human.parcellated_thickness.xlsx')\n",
    "df_human.head()\n",
    "\n",
    "df_human_normalize= {}\n",
    "features = df_human.columns[2:]  # features are from the 2nd column to the last\n",
    "\n",
    "# Z-score normalization\n",
    "for feature in features:\n",
    "    mean = df_human[feature].mean()\n",
    "    std = df_human[feature].std()\n",
    "    df_human_normalize[feature] = (df_human[feature] - mean) / std\n",
    "\n",
    "# Save the Human normalized data\n",
    "df_human_normalize = pd.DataFrame(df_human_normalize)\n",
    "label_human = df_human.iloc[:, :2]\n",
    "df_human_normalize = pd.concat([label_human, df_human_normalize], axis=1)\n",
    "df_human_normalize.to_excel('data/normalized/Human_normalized_parcellated_thickness.xlsx', index=False)\n",
    "\n",
    "df_human_normalize_markov = df_human_normalize.loc[:, ~df_human_normalize.columns.str.startswith('Schaefer')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14465/14465 [00:10<00:00, 1427.51it/s]\n"
     ]
    }
   ],
   "source": [
    "df_sex = pd.read_excel('data/subjects_age_sex_data_MRI.xlsx')\n",
    "\n",
    "## set up training data\n",
    "X1 = []\n",
    "X2 = []\n",
    "y_human = []\n",
    "IDs = set(df_human_normalize_markov['sid'])\n",
    "ref_IDs = set(df_sex['ID'])\n",
    "\n",
    "for subject in tqdm(IDs):\n",
    "    if subject in ref_IDs:\n",
    "        features = np.array(df_human_normalize_markov[df_human_normalize_markov['sid']==subject]).reshape(-1)[2:]\n",
    "        gender = list(df_sex[df_sex['ID']==subject]['Sex'])\n",
    "        sex = int(gender[0]=='FEMALE')\n",
    "\n",
    "        X1.append(list(features[:182]))\n",
    "        X2.append(list(features[182:]))\n",
    "        y_human.append(sex)\n",
    "\n",
    "X1_human = np.array(X1)\n",
    "X2_human = np.array(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_human = np.nan_to_num(X1_human)\n",
    "X2_human = np.nan_to_num(X2_human)\n",
    "X_human = np.concatenate((X1_human,X2_human),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on SPORF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [15:30<00:00, 186.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for n_estimator =  2000  is  [np.float64(0.7248826291079812), np.float64(0.7370892018779343), np.float64(0.7234741784037558), np.float64(0.7084507042253522), np.float64(0.7286384976525822)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 5 into shape (5,5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m sporf_accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((sporf_accuracy, accuracies))\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy for n_estimator = \u001b[39m\u001b[38;5;124m'\u001b[39m, n_estimator,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m, accuracies)\n\u001b[1;32m---> 16\u001b[0m sporf_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43msporf_accuracy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(sporf_accuracy)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 5 into shape (5,5)"
     ]
    }
   ],
   "source": [
    "### SPORF ###\n",
    "reps = 5\n",
    "sporf_accuracy = []\n",
    "n_estimator = 2000\n",
    "accuracies = []\n",
    "for ii in tqdm(range(reps)):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "                    X1_human, y_human, train_size=0.8, random_state=ii, stratify=y_human)\n",
    "    clf = ObliqueRandomForestClassifier(n_estimators=n_estimator, n_jobs=-1, feature_combinations=3.47, max_features=0.993)\n",
    "    clf.fit(x_train, y_train)\n",
    "    accuracy = np.mean(clf.predict(x_test)==y_test)\n",
    "    accuracies.append(accuracy)\n",
    "sporf_accuracy = np.concatenate((sporf_accuracy, accuracies))\n",
    "print('Accuracy for n_estimator = ', n_estimator,' is ', accuracies)\n",
    "\n",
    "#sporf_accuracy = sporf_accuracy.reshape(5, 5)\n",
    "print(sporf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72488263, 0.7370892 , 0.72347418, 0.7084507 , 0.7286385 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sporf_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame work to test trunk simulation on multiple supervised tree classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the supervised tree estimators from the treeple package.\n",
    "# (Make sure treeple is installed and the estimators below exist in your version.)\n",
    "import treeple.ensemble._supervised_forest\n",
    "from treeple.ensemble._supervised_forest import (ObliqueRandomForestClassifier,\n",
    "                     ExtraObliqueRandomForestClassifier, \n",
    "                     PatchObliqueRandomForestClassifier)\n",
    "\n",
    "# --- Parameters ---\n",
    "reps = 5  # number of repetitions for each configuration\n",
    "n_estimator = 500  # parameter for ensemble classifiers\n",
    "# List of noise dimensions to add (0 means no extra noise; higher values add more noise)\n",
    "noise_dims_list = [0, 10, 20, 30, 40]\n",
    "\n",
    "# Define a dictionary of estimator constructors.\n",
    "# We wrap each estimator in a lambda so that a fresh instance is created for each run.\n",
    "estimators = {\n",
    "    \"ObliqueRandomForest\": lambda: ObliqueRandomForestClassifier(n_estimators=n_estimator, n_jobs=-1, feature_combinations=2.3),\n",
    "    \"ExtraObliqueRandomForest\": lambda: ExtraObliqueRandomForestClassifier(n_estimators=n_estimator, n_jobs=-1),\n",
    "    \"PatchObliqueRandomForestClassifier\": lambda: PatchObliqueRandomForestClassifier(n_estimators=n_estimator, n_jobs=-1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing with 0 noisy dimensions added ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ObliqueRandomForest, noise dims=0:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# This dictionary will store results for each estimator and each noise level.\n",
    "# The structure will be: results[estimator_name][noise_dim] = {\"accuracy\": avg_accuracy, \"time\": avg_train_time}\n",
    "results = {est_name: {} for est_name in estimators.keys()}\n",
    "\n",
    "# For each noise level, add that many extra columns (noise features) to your original data.\n",
    "for noise_dim in noise_dims_list:\n",
    "    print(f\"\\n=== Testing with {noise_dim} noisy dimensions added ===\")\n",
    "    \n",
    "    # For each estimator from treeple\n",
    "    for est_name, est_constructor in estimators.items():\n",
    "        accuracies = []\n",
    "        train_times = []\n",
    "        \n",
    "        # Repeat the experiment several times to average out randomness.\n",
    "        for rep in tqdm(range(reps), desc=f\"{est_name}, noise dims={noise_dim}\"):\n",
    "            # Create noise features: shape = (n_samples, noise_dim)\n",
    "            if noise_dim > 0:\n",
    "                noise_features = np.random.normal(0, 1, size=(X1_human.shape[0], noise_dim))\n",
    "                X_sim = np.concatenate([X1_human, noise_features], axis=1)\n",
    "            else:\n",
    "                X_sim = X1_human.copy()\n",
    "            \n",
    "            # Split the data (80% training, 20% testing) with stratification\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_sim, y_human, train_size=0.8, random_state=rep, stratify=y_human)\n",
    "            \n",
    "            # Initialize the classifier\n",
    "            clf = est_constructor()\n",
    "            \n",
    "            # Record training time\n",
    "            start_time = time.time()\n",
    "            clf.fit(X_train, y_train)\n",
    "            end_time = time.time()\n",
    "            runtime = end_time - start_time\n",
    "            \n",
    "            # Compute accuracy on the test set\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy = np.mean(y_pred == y_test)\n",
    "            \n",
    "            accuracies.append(accuracy)\n",
    "            train_times.append(runtime)\n",
    "        \n",
    "        # Save average results for this estimator and noise level.\n",
    "        avg_accuracy = np.mean(accuracies)\n",
    "        avg_time = np.mean(train_times)\n",
    "        results[est_name][noise_dim] = {\"accuracy\": avg_accuracy, \"time\": avg_time}\n",
    "        print(f\"{est_name} | Noise dims: {noise_dim} | Avg. Accuracy: {avg_accuracy:.4f} | Avg. Training Time: {avg_time:.4f} sec\")\n",
    "\n",
    "# Optionally, print a summary of all results.\n",
    "print(\"\\n=== Summary of Results ===\")\n",
    "for est_name, noise_results in results.items():\n",
    "    print(f\"\\nEstimator: {est_name}\")\n",
    "    for noise_dim, metrics in noise_results.items():\n",
    "        print(f\"  Noise dims: {noise_dim} | Accuracy: {metrics['accuracy']:.4f} | Training Time: {metrics['time']:.4f} sec\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "treeple_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
