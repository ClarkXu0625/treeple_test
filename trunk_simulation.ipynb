{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import\n",
    "import treeple.tree._honest_tree\n",
    "from treeple.ensemble._supervised_forest import ObliqueRandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature normalization\n",
    "df_human = pd.read_excel('data/Human.parcellated_thickness.xlsx')\n",
    "df_human.head()\n",
    "\n",
    "df_human_normalize= {}\n",
    "features = df_human.columns[2:]  # features are from the 2nd column to the last\n",
    "\n",
    "# Z-score normalization\n",
    "for feature in features:\n",
    "    mean = df_human[feature].mean()\n",
    "    std = df_human[feature].std()\n",
    "    df_human_normalize[feature] = (df_human[feature] - mean) / std\n",
    "\n",
    "# Save the Human normalized data\n",
    "df_human_normalize = pd.DataFrame(df_human_normalize)\n",
    "label_human = df_human.iloc[:, :2]\n",
    "df_human_normalize = pd.concat([label_human, df_human_normalize], axis=1)\n",
    "df_human_normalize.to_excel('data/normalized/Human_normalized_parcellated_thickness.xlsx', index=False)\n",
    "\n",
    "df_human_normalize_markov = df_human_normalize.loc[:, ~df_human_normalize.columns.str.startswith('Schaefer')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14465/14465 [00:10<00:00, 1427.51it/s]\n"
     ]
    }
   ],
   "source": [
    "df_sex = pd.read_excel('data/subjects_age_sex_data_MRI.xlsx')\n",
    "\n",
    "## set up training data\n",
    "X1 = []\n",
    "X2 = []\n",
    "y_human = []\n",
    "IDs = set(df_human_normalize_markov['sid'])\n",
    "ref_IDs = set(df_sex['ID'])\n",
    "\n",
    "for subject in tqdm(IDs):\n",
    "    if subject in ref_IDs:\n",
    "        features = np.array(df_human_normalize_markov[df_human_normalize_markov['sid']==subject]).reshape(-1)[2:]\n",
    "        gender = list(df_sex[df_sex['ID']==subject]['Sex'])\n",
    "        sex = int(gender[0]=='FEMALE')\n",
    "\n",
    "        X1.append(list(features[:182]))\n",
    "        X2.append(list(features[182:]))\n",
    "        y_human.append(sex)\n",
    "\n",
    "X1_human = np.array(X1)\n",
    "X2_human = np.array(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_human = np.nan_to_num(X1_human)\n",
    "X2_human = np.nan_to_num(X2_human)\n",
    "X_human = np.concatenate((X1_human,X2_human),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on SPORF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [15:30<00:00, 186.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for n_estimator =  2000  is  [np.float64(0.7248826291079812), np.float64(0.7370892018779343), np.float64(0.7234741784037558), np.float64(0.7084507042253522), np.float64(0.7286384976525822)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 5 into shape (5,5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m sporf_accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((sporf_accuracy, accuracies))\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy for n_estimator = \u001b[39m\u001b[38;5;124m'\u001b[39m, n_estimator,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m, accuracies)\n\u001b[1;32m---> 16\u001b[0m sporf_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43msporf_accuracy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(sporf_accuracy)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 5 into shape (5,5)"
     ]
    }
   ],
   "source": [
    "### SPORF ###\n",
    "reps = 5\n",
    "sporf_accuracy = []\n",
    "n_estimator = 2000\n",
    "accuracies = []\n",
    "for ii in tqdm(range(reps)):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "                    X1_human, y_human, train_size=0.8, random_state=ii, stratify=y_human)\n",
    "    clf = ObliqueRandomForestClassifier(n_estimators=n_estimator, n_jobs=-1, feature_combinations=3.47, max_features=0.993)\n",
    "    clf.fit(x_train, y_train)\n",
    "    accuracy = np.mean(clf.predict(x_test)==y_test)\n",
    "    accuracies.append(accuracy)\n",
    "sporf_accuracy = np.concatenate((sporf_accuracy, accuracies))\n",
    "print('Accuracy for n_estimator = ', n_estimator,' is ', accuracies)\n",
    "\n",
    "#sporf_accuracy = sporf_accuracy.reshape(5, 5)\n",
    "print(sporf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72488263, 0.7370892 , 0.72347418, 0.7084507 , 0.7286385 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sporf_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame work to test trunk simulation on multiple supervised tree classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the supervised tree estimators from the treeple package.\n",
    "# (Make sure treeple is installed and the estimators below exist in your version.)\n",
    "import treeple.ensemble._supervised_forest\n",
    "from treeple.ensemble._supervised_forest import (ObliqueRandomForestClassifier,\n",
    "                     ExtraObliqueRandomForestClassifier, \n",
    "                     PatchObliqueRandomForestClassifier)\n",
    "\n",
    "# --- Parameters ---\n",
    "reps = 5  # number of repetitions for each configuration\n",
    "n_estimator = 500  # parameter for ensemble classifiers\n",
    "# List of noise dimensions to add (0 means no extra noise; higher values add more noise)\n",
    "noise_dims_list = [0, 10, 20, 30, 40]\n",
    "\n",
    "# Define a dictionary of estimator constructors.\n",
    "# We wrap each estimator in a lambda so that a fresh instance is created for each run.\n",
    "estimators = {\n",
    "    \"ObliqueRandomForest\": lambda: ObliqueRandomForestClassifier(n_estimators=n_estimator, n_jobs=-1, feature_combinations=2.3),\n",
    "    \"ExtraObliqueRandomForest\": lambda: ExtraObliqueRandomForestClassifier(n_estimators=n_estimator, n_jobs=-1),\n",
    "    \"PatchObliqueRandomForestClassifier\": lambda: PatchObliqueRandomForestClassifier(n_estimators=n_estimator, n_jobs=-1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing with 0 noisy dimensions added ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ObliqueRandomForest, noise dims=0: 100%|██████████| 5/5 [02:59<00:00, 35.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObliqueRandomForest | Noise dims: 0 | Avg. Accuracy: 0.7055 | Avg. Training Time: 33.2706 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExtraObliqueRandomForest, noise dims=0: 100%|██████████| 5/5 [02:56<00:00, 35.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraObliqueRandomForest | Noise dims: 0 | Avg. Accuracy: 0.6828 | Avg. Training Time: 32.2633 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PatchObliqueRandomForestClassifier, noise dims=0: 100%|██████████| 5/5 [02:57<00:00, 35.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchObliqueRandomForestClassifier | Noise dims: 0 | Avg. Accuracy: 0.6110 | Avg. Training Time: 31.9932 sec\n",
      "\n",
      "=== Testing with 10 noisy dimensions added ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ObliqueRandomForest, noise dims=10:  60%|██████    | 3/5 [02:23<01:35, 47.98s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m runtime \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Compute accuracy on the test set\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(y_pred \u001b[38;5;241m==\u001b[39m y_test)\n\u001b[0;32m     40\u001b[0m accuracies\u001b[38;5;241m.\u001b[39mappend(accuracy)\n",
      "File \u001b[1;32mc:\\Users\\clark\\anaconda3\\envs\\treeple_new\\lib\\site-packages\\treeple\\_lib\\sklearn\\ensemble\\_forest.py:1471\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   1451\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1452\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m   1453\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1471\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1474\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\clark\\anaconda3\\envs\\treeple_new\\lib\\site-packages\\treeple\\_lib\\sklearn\\ensemble\\_forest.py:1532\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1527\u001b[0m all_proba \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1528\u001b[0m     np\u001b[38;5;241m.\u001b[39mzeros((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], j), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m   1529\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_)\n\u001b[0;32m   1530\u001b[0m ]\n\u001b[0;32m   1531\u001b[0m lock \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()\n\u001b[1;32m-> 1532\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msharedmem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_accumulate_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\n\u001b[0;32m   1535\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m proba \u001b[38;5;129;01min\u001b[39;00m all_proba:\n\u001b[0;32m   1538\u001b[0m     proba \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)\n",
      "File \u001b[1;32mc:\\Users\\clark\\anaconda3\\envs\\treeple_new\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\clark\\anaconda3\\envs\\treeple_new\\lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\clark\\anaconda3\\envs\\treeple_new\\lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clark\\anaconda3\\envs\\treeple_new\\lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimators = {\n",
    "    \"ObliqueRandomForest\": lambda: ObliqueRandomForestClassifier(n_estimators=n_estimator, n_jobs=0, feature_combinations=2.3),\n",
    "    \"ExtraObliqueRandomForest\": lambda: ExtraObliqueRandomForestClassifier(n_estimators=n_estimator, n_jobs=0),\n",
    "    \"PatchObliqueRandomForestClassifier\": lambda: PatchObliqueRandomForestClassifier(n_estimators=n_estimator, n_jobs=0)\n",
    "}\n",
    "# This dictionary will store results for each estimator and each noise level.\n",
    "# The structure will be: results[estimator_name][noise_dim] = {\"accuracy\": avg_accuracy, \"time\": avg_train_time}\n",
    "results = {est_name: {} for est_name in estimators.keys()}\n",
    "\n",
    "# For each noise level, add that many extra columns (noise features) to your original data.\n",
    "for noise_dim in noise_dims_list:\n",
    "    print(f\"\\n=== Testing with {noise_dim} noisy dimensions added ===\")\n",
    "    \n",
    "    # For each estimator from treeple\n",
    "    for est_name, est_constructor in estimators.items():\n",
    "        accuracies = []\n",
    "        train_times = []\n",
    "        \n",
    "        # Repeat the experiment several times to average out randomness.\n",
    "        for rep in tqdm(range(reps), desc=f\"{est_name}, noise dims={noise_dim}\"):\n",
    "            # Create noise features: shape = (n_samples, noise_dim)\n",
    "            if noise_dim > 0:\n",
    "                noise_features = np.random.normal(0, 1, size=(X1_human.shape[0], noise_dim))\n",
    "                X_sim = np.concatenate([X1_human, noise_features], axis=1)\n",
    "            else:\n",
    "                X_sim = X1_human.copy()\n",
    "            \n",
    "            # Split the data (80% training, 20% testing) with stratification\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_sim, y_human, train_size=0.8, random_state=rep, stratify=y_human)\n",
    "            \n",
    "            # Initialize the classifier\n",
    "            clf = est_constructor()\n",
    "            \n",
    "            # Record training time\n",
    "            start_time = time.time()\n",
    "            clf.fit(X_train, y_train)\n",
    "            end_time = time.time()\n",
    "            runtime = end_time - start_time\n",
    "            \n",
    "            # Compute accuracy on the test set\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy = np.mean(y_pred == y_test)\n",
    "            \n",
    "            accuracies.append(accuracy)\n",
    "            train_times.append(runtime)\n",
    "        \n",
    "        # Save average results for this estimator and noise level.\n",
    "        avg_accuracy = np.mean(accuracies)\n",
    "        avg_time = np.mean(train_times)\n",
    "        results[est_name][noise_dim] = {\"accuracy\": avg_accuracy, \"time\": avg_time}\n",
    "        print(f\"{est_name} | Noise dims: {noise_dim} | Avg. Accuracy: {avg_accuracy:.4f} | Avg. Training Time: {avg_time:.4f} sec\")\n",
    "\n",
    "# Optionally, print a summary of all results.\n",
    "print(\"\\n=== Summary of Results ===\")\n",
    "for est_name, noise_results in results.items():\n",
    "    print(f\"\\nEstimator: {est_name}\")\n",
    "    for noise_dim, metrics in noise_results.items():\n",
    "        print(f\"  Noise dims: {noise_dim} | Accuracy: {metrics['accuracy']:.4f} | Training Time: {metrics['time']:.4f} sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually set n_jobs to -2 using joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing with 0 noisy dimensions added ===\n",
      "ObliqueRandomForest | Noise dims: 0 | Avg. Accuracy: 0.7078 | Avg. Training Time: 9.1636 sec\n",
      "ExtraObliqueRandomForest | Noise dims: 0 | Avg. Accuracy: 0.6833 | Avg. Training Time: 3.6016 sec\n",
      "PatchObliqueRandomForestClassifier | Noise dims: 0 | Avg. Accuracy: 0.6107 | Avg. Training Time: 23.2477 sec\n",
      "\n",
      "=== Testing with 10 noisy dimensions added ===\n",
      "ObliqueRandomForest | Noise dims: 10 | Avg. Accuracy: 0.7039 | Avg. Training Time: 9.4144 sec\n",
      "ExtraObliqueRandomForest | Noise dims: 10 | Avg. Accuracy: 0.6756 | Avg. Training Time: 3.8736 sec\n",
      "PatchObliqueRandomForestClassifier | Noise dims: 10 | Avg. Accuracy: 0.6093 | Avg. Training Time: 29.3481 sec\n",
      "\n",
      "=== Testing with 20 noisy dimensions added ===\n",
      "ObliqueRandomForest | Noise dims: 20 | Avg. Accuracy: 0.6984 | Avg. Training Time: 10.1348 sec\n",
      "ExtraObliqueRandomForest | Noise dims: 20 | Avg. Accuracy: 0.6706 | Avg. Training Time: 4.7513 sec\n",
      "PatchObliqueRandomForestClassifier | Noise dims: 20 | Avg. Accuracy: 0.6075 | Avg. Training Time: 32.6277 sec\n",
      "\n",
      "=== Testing with 30 noisy dimensions added ===\n",
      "ObliqueRandomForest | Noise dims: 30 | Avg. Accuracy: 0.6961 | Avg. Training Time: 10.9268 sec\n",
      "ExtraObliqueRandomForest | Noise dims: 30 | Avg. Accuracy: 0.6625 | Avg. Training Time: 4.6837 sec\n",
      "PatchObliqueRandomForestClassifier | Noise dims: 30 | Avg. Accuracy: 0.6032 | Avg. Training Time: 33.7107 sec\n",
      "\n",
      "=== Testing with 40 noisy dimensions added ===\n",
      "ObliqueRandomForest | Noise dims: 40 | Avg. Accuracy: 0.6920 | Avg. Training Time: 11.0547 sec\n",
      "ExtraObliqueRandomForest | Noise dims: 40 | Avg. Accuracy: 0.6589 | Avg. Training Time: 4.9646 sec\n",
      "PatchObliqueRandomForestClassifier | Noise dims: 40 | Avg. Accuracy: 0.6017 | Avg. Training Time: 29.4128 sec\n",
      "\n",
      "=== Summary of Results ===\n",
      "\n",
      "Estimator: ObliqueRandomForest\n",
      "  Noise dims: 0 | Accuracy: 0.7078 | Training Time: 9.1636 sec\n",
      "  Noise dims: 10 | Accuracy: 0.7039 | Training Time: 9.4144 sec\n",
      "  Noise dims: 20 | Accuracy: 0.6984 | Training Time: 10.1348 sec\n",
      "  Noise dims: 30 | Accuracy: 0.6961 | Training Time: 10.9268 sec\n",
      "  Noise dims: 40 | Accuracy: 0.6920 | Training Time: 11.0547 sec\n",
      "\n",
      "Estimator: ExtraObliqueRandomForest\n",
      "  Noise dims: 0 | Accuracy: 0.6833 | Training Time: 3.6016 sec\n",
      "  Noise dims: 10 | Accuracy: 0.6756 | Training Time: 3.8736 sec\n",
      "  Noise dims: 20 | Accuracy: 0.6706 | Training Time: 4.7513 sec\n",
      "  Noise dims: 30 | Accuracy: 0.6625 | Training Time: 4.6837 sec\n",
      "  Noise dims: 40 | Accuracy: 0.6589 | Training Time: 4.9646 sec\n",
      "\n",
      "Estimator: PatchObliqueRandomForestClassifier\n",
      "  Noise dims: 0 | Accuracy: 0.6107 | Training Time: 23.2477 sec\n",
      "  Noise dims: 10 | Accuracy: 0.6093 | Training Time: 29.3481 sec\n",
      "  Noise dims: 20 | Accuracy: 0.6075 | Training Time: 32.6277 sec\n",
      "  Noise dims: 30 | Accuracy: 0.6032 | Training Time: 33.7107 sec\n",
      "  Noise dims: 40 | Accuracy: 0.6017 | Training Time: 29.4128 sec\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {est_name: {} for est_name in estimators.keys()}\n",
    "\n",
    "# Define the simulation function for one run.\n",
    "def run_simulation(estimator_constructor, noise_dim, rep, X_data, y_data):\n",
    "    # Add noise dimensions if needed.\n",
    "    if noise_dim > 0:\n",
    "        noise_features = np.random.normal(0, 1, size=(X_data.shape[0], noise_dim))\n",
    "        X_sim = np.concatenate([X_data, noise_features], axis=1)\n",
    "    else:\n",
    "        X_sim = X_data.copy()\n",
    "    \n",
    "    # Split the data (80% training, 20% testing) with stratification.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_sim, y_data, train_size=0.8, random_state=rep, stratify=y_data)\n",
    "    \n",
    "    clf = estimator_constructor()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    accuracy = np.mean(clf.predict(X_test) == y_test)\n",
    "    return accuracy, train_time\n",
    "\n",
    "# Assume X1_human and y_human are your pre-loaded cortical thickness data and corresponding labels.\n",
    "# For each noise level, run the simulation for each estimator.\n",
    "for noise_dim in noise_dims_list:\n",
    "    print(f\"\\n=== Testing with {noise_dim} noisy dimensions added ===\")\n",
    "    for est_name, est_constructor in estimators.items():\n",
    "        # Run simulation reps in parallel.\n",
    "        simulation_results = Parallel(n_jobs=-2)(\n",
    "            delayed(run_simulation)(est_constructor, noise_dim, rep, X1_human, y_human) \n",
    "            for rep in range(reps)\n",
    "        )\n",
    "        # Unpack the results.\n",
    "        accuracies, times = zip(*simulation_results)\n",
    "        avg_accuracy = np.mean(accuracies)\n",
    "        avg_time = np.mean(times)\n",
    "        results[est_name][noise_dim] = {\"accuracy\": avg_accuracy, \"time\": avg_time}\n",
    "        print(f\"{est_name} | Noise dims: {noise_dim} | Avg. Accuracy: {avg_accuracy:.4f} | Avg. Training Time: {avg_time:.4f} sec\")\n",
    "\n",
    "# Optionally, print a summary of all results.\n",
    "print(\"\\n=== Summary of Results ===\")\n",
    "for est_name, noise_results in results.items():\n",
    "    print(f\"\\nEstimator: {est_name}\")\n",
    "    for noise_dim, metrics in noise_results.items():\n",
    "        print(f\"  Noise dims: {noise_dim} | Accuracy: {metrics['accuracy']:.4f} | Training Time: {metrics['time']:.4f} sec\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "treeple_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
